{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZAbkgEn_jor"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#funcao de ativacao (sigmoide)\n",
        "def sigmoid(x, derivative=False):\n",
        "  s = 1.0 / (1.0 + np.exp(-x))\n",
        "  if derivative:\n",
        "      return s * (1 - s)\n",
        "  return s\n",
        "\n",
        "#funcao de ativacao (relu)\n",
        "def relu ( x, derivative= False ):\n",
        "  if derivative:\n",
        "      return  1 * (x > 0 )\n",
        "\n",
        "  return np.maximum( 0 , x)\n",
        "\n",
        "#funcao de ativacao (softmax)\n",
        "def softmax(x, derivative=False):\n",
        "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    probs = exps / np.sum(exps, axis=1, keepdims=True)\n",
        "    if derivative:\n",
        "        return probs\n",
        "    return probs\n",
        "\n",
        "#funcao de erro quadratico medio\n",
        "def mse(y_true, y_pred, derivative=False):\n",
        "    if derivative:\n",
        "        return (y_pred - y_true)\n",
        "    return np.mean(0.5 * (y_true - y_pred) ** 2)"
      ],
      "metadata": {
        "id": "qcfRu7tLEr4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-Network parameters\n",
        "m           = 0.9            #momentum\n",
        "a           = 0.01           #taxa de aprendizado\n",
        "init_method = 'xavier'       #tecnica para ajuste dos pesos\n",
        "hidden_f    = sigmoid        #funcao de ativacao para camada oculta\n",
        "output_f    = sigmoid        #funcao de ativacao camada de saida\n",
        "epochs      = 1000\n",
        "batch_size  = 0\n",
        "e_threshold = 1E-5           #criterio de parada antecipada\n",
        "\n",
        "network_topology = [2, 3, 1] #2 neuronios de entrada, 3 na camada oculta, 1 na saida\n",
        "\n",
        "#porta xor (entrada)\n",
        "xor = np.array([[0,0],\n",
        "                [0,1],\n",
        "                [1,0],\n",
        "                [1,1]])\n",
        "\n",
        "#saida esperada da porta xor\n",
        "saida_esperada = np.array([[0],\n",
        "                        [1],\n",
        "                        [1],\n",
        "                        [0]])"
      ],
      "metadata": {
        "id": "hCcWKdKhDL2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementação do Backpropagation\n",
        "class Backpropagation:\n",
        "\n",
        "    def __init__(self,\n",
        "                 topology,\n",
        "                 learning_rate,\n",
        "                 momentum,\n",
        "                 hidden_activation_func=sigmoid,\n",
        "                 output_activation_func=sigmoid,\n",
        "                 error_function=mse,\n",
        "                 init_method='xavier',\n",
        "                 seed=None):\n",
        "\n",
        "        self.topology = topology\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum = momentum\n",
        "        self.hidden_activation = hidden_activation_func\n",
        "        self.output_activation = output_activation_func\n",
        "\n",
        "        self.error_function = mse\n",
        "\n",
        "        # Inicializações básicas\n",
        "        self.size = len(topology) - 1\n",
        "        self.weights = []\n",
        "        self.bias = []\n",
        "        for i in range(self.size):\n",
        "            in_neurons = topology[i]\n",
        "            out_neurons = topology[i + 1]\n",
        "            limit = np.sqrt(1 / in_neurons)\n",
        "            W = np.random.uniform(-limit, limit, (in_neurons, out_neurons))\n",
        "            b = np.zeros((1, out_neurons))\n",
        "            self.weights.append(W)\n",
        "            self.bias.append(b)\n",
        "\n",
        "\n",
        "    def feedforward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.netIns = []\n",
        "        self.deltas = [None] * self.size\n",
        "\n",
        "        layer_input = inputs # Inicializa com entradas da rede\n",
        "        self.netOuts = []\n",
        "\n",
        "        for i in range(self.size):\n",
        "            # Calcula o net input\n",
        "            netIn = np.dot(layer_input, self.weights[i]) + self.bias[i]\n",
        "            self.netIns.append(netIn)\n",
        "\n",
        "            # Aplica a função de ativação\n",
        "            if i == self.size - 1:\n",
        "                # Camada de saída\n",
        "                netOut = self.output_activation(netIn)\n",
        "            else:\n",
        "                # Camadas ocultas\n",
        "                netOut = self.hidden_activation(netIn)\n",
        "\n",
        "            self.netOuts.append(netOut)\n",
        "            layer_input = netOut\n",
        "\n",
        "        return self.netOuts[-1] # Retorna a saída da última camada\n",
        "\n",
        "\n",
        "    #calcular gradiente para camada de saida\n",
        "    def backprop(self, target, output, error_func):\n",
        "        # Percorre camadas de trás pra frente\n",
        "        for i in range(self.size):\n",
        "            back_index = self.size - 1 - i  # camada atual (de trás pra frente)\n",
        "\n",
        "            # --- CAMADA DE SAÍDA ---\n",
        "            if i == 0:\n",
        "                # Derivadas\n",
        "                d_activ = self.output_activation(self.netIns[back_index], derivative=True) #ativacao\n",
        "                d_error = error_func(target, output, derivative=True)  #erro\n",
        "                delta = d_error * d_activ  # erro local (gradiente)\n",
        "\n",
        "            # --- CAMADAS OCULTAS ---\n",
        "            else:\n",
        "                next_index = back_index + 1\n",
        "                W_next = self.weights[next_index]\n",
        "                delta_next = self.deltas[next_index]\n",
        "                d_activ = self.hidden_activation(self.netIns[back_index], derivative=True)\n",
        "\n",
        "                # Propagação do erro\n",
        "                delta = np.dot(delta_next, W_next.T) * d_activ\n",
        "\n",
        "            # Guarda o delta atual\n",
        "            self.deltas[back_index] = delta\n",
        "\n",
        "            # --- GRADIENTES ---\n",
        "            if back_index == 0:\n",
        "                # entrada original da rede\n",
        "                layer_input = self.inputs\n",
        "            else:\n",
        "                layer_input = self.netOuts[back_index - 1]\n",
        "\n",
        "            gradient_mat = np.dot(layer_input.T, delta)\n",
        "            bias_grad_mat = np.sum(delta, axis=0, keepdims=True)\n",
        "\n",
        "            # --- ATUALIZA PESOS ---\n",
        "            self._gradient_descent(\n",
        "                layer_idx=back_index,\n",
        "                gradient_mat=gradient_mat,\n",
        "                bias_gradient=bias_grad_mat\n",
        "            )\n",
        "\n",
        "\n",
        "    def _gradient_descent(self, layer_idx, gradient_mat, bias_gradient):\n",
        "        self.weights[layer_idx] -= self.learning_rate * gradient_mat\n",
        "        self.bias[layer_idx] -= self.learning_rate * bias_gradient\n",
        "\n",
        "    def train(self, inputs, targets, epochs=10000, error_threshold=1e-3):\n",
        "        for epoch in range(epochs):\n",
        "            # Feedforward\n",
        "            outputs = self.feedforward(inputs)\n",
        "\n",
        "            # Calcula erro\n",
        "            error = self.error_function(targets, outputs)\n",
        "\n",
        "            # Backpropagation\n",
        "            self.backprop(targets, outputs, self.error_function)\n",
        "\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Época {epoch} - Erro: {error:.6f}\")\n",
        "            if error <= error_threshold:\n",
        "                break"
      ],
      "metadata": {
        "id": "d9CStdzS_n9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede = Backpropagation(\n",
        "    topology = network_topology,\n",
        "    learning_rate = a,\n",
        "    momentum = m,\n",
        "    hidden_activation_func = hidden_f,\n",
        "    output_activation_func = output_f,\n",
        "    init_method = init_method\n",
        ")\n",
        "\n",
        "error = rede.train(\n",
        "    xor,\n",
        "    saida_esperada,\n",
        "    epochs=epochs,\n",
        "    error_threshold=e_threshold\n",
        ")\n",
        "\n",
        "print(f\"\\n\\n{'='*40}\\nTraining XOR gate:\\n{'='*40}\\n\")\n",
        "\n",
        "for i, sample in enumerate(xor):\n",
        "    output = rede.feedforward(sample.reshape(1, -1))\n",
        "    sample_error = mse(saida_esperada[i:i+1], output)\n",
        "    print(f\"Testing Network:\\n\\tvetor de entrada : {sample}\\n\\tvetor de saída   : {output}\\n\\tsaída esperada   : {saida_esperada[i]}\")\n",
        "    print(f\"\\tNetwork error    : {sample_error:.3e}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flqhh1s7EXej",
        "outputId": "7880b8f5-5134-4da6-cc4f-2ed3a15867c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0 - Erro: 0.126440\n",
            "\n",
            "\n",
            "========================================\n",
            "Training XOR gate:\n",
            "========================================\n",
            "\n",
            "Testing Network:\n",
            "\tvetor de entrada : [0 0]\n",
            "\tvetor de saída   : [[0.4975045]]\n",
            "\tsaída esperada   : [0]\n",
            "\tNetwork error    : 1.238e-01\n",
            "\n",
            "Testing Network:\n",
            "\tvetor de entrada : [0 1]\n",
            "\tvetor de saída   : [[0.49628398]]\n",
            "\tsaída esperada   : [1]\n",
            "\tNetwork error    : 1.269e-01\n",
            "\n",
            "Testing Network:\n",
            "\tvetor de entrada : [1 0]\n",
            "\tvetor de saída   : [[0.50385124]]\n",
            "\tsaída esperada   : [1]\n",
            "\tNetwork error    : 1.231e-01\n",
            "\n",
            "Testing Network:\n",
            "\tvetor de entrada : [1 1]\n",
            "\tvetor de saída   : [[0.50267732]]\n",
            "\tsaída esperada   : [0]\n",
            "\tNetwork error    : 1.263e-01\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b758dc0",
        "outputId": "3adce866-973c-446d-eb52-7d20c67d4319"
      },
      "source": [
        "# teste com ruído\n",
        "ruidoTeste = 0.1\n",
        "ruido = np.random.uniform(-ruidoTeste, ruidoTeste, size=xor.shape)\n",
        "xor_ruido = xor + ruido\n",
        "\n",
        "print(\"Dados XOR originais:\\n\", xor)\n",
        "print(\"\\nDados XOR com ruído:\\n\", xor_ruido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados XOR originais:\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "\n",
            "Dados XOR com ruído:\n",
            " [[-0.08231907 -0.04231923]\n",
            " [-0.0304607   1.04752482]\n",
            " [ 1.04379622  0.00460797]\n",
            " [ 0.92318684  0.91058128]]\n"
          ]
        }
      ]
    }
  ]
}